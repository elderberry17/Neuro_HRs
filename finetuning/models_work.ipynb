{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models_work.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install required enviroment"
      ],
      "metadata": {
        "id": "w6mpHAX0hZfq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyiAOsYiWhr9"
      },
      "source": [
        "!pip install torch==1.5.0\n",
        "!pip3 install transformers==3.5.0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KafAMnElOap"
      },
      "source": [
        "!git clone  https://github.com/sberbank-ai/ru-gpts"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av9MZQFjlRg-"
      },
      "source": [
        "!mkdir models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvMSUQ2JU0_a"
      },
      "source": [
        "# Load packages and original Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkNDvjSviw8X"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import regex as re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_ENt_PS3qcS"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead, GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn3qTXGRmgCD",
        "outputId": "e99843ab-2eab-4586-c601-819ecd3b40e3"
      },
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fef6fc8e590>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otoFB8D5V6Xa"
      },
      "source": [
        "Functions to remove emoji from texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rOFwGmaj03u"
      },
      "source": [
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  \n",
        "        u\"\\U0001F300-\\U0001F5FF\"  \n",
        "        u\"\\U0001F680-\\U0001F6FF\"  \n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
        "        u\"\\U00002500-\\U00002BEF\"  \n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  \n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "\n",
        "    return regrex_pattern.sub(r'', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh5VU1JMj4Np"
      },
      "source": [
        "def csv_deEmojify(dfs):\n",
        "  for i in range(dfs.shape[0]):\n",
        "    for j in range(dfs.shape[1]):\n",
        "      splited = (str(dfs.iloc[i,j]).split())\n",
        "      for u in range(len(splited)):\n",
        "        splited[u] = deEmojify(splited[u])\n",
        "      res_str = ' '.join(splited)\n",
        "      dfs.iloc[i,j] = res_str\n",
        "  return dfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JK9Ip9akZUj"
      },
      "source": [
        "Save data to the data variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxSHiIAqWLPr"
      },
      "source": [
        "def preproc_data(dataset):\n",
        "  dataset = csv_deEmojify(dataset)\n",
        "  try:\n",
        "    dataset = dataset.rename(columns={\"Заголовок + конец сообщения\": \"start_end\", \"Только заголовок\": \"start\"})\n",
        "    dataset = dataset[[\"start_end\", \"start\"]]\n",
        "  except:\n",
        "    print(\"noup\")\n",
        "  \n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIDz16AVaVOS",
        "outputId": "6b677c94-9c80-455f-8e32-3294801a559d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N-lD5qKk9mC"
      },
      "source": [
        "data = pd.read_excel(\"/content/drive/MyDrive/course_work/Headings_wo_emoji.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lB1L7F4hkwv"
      },
      "source": [
        "### Extract prefixes for geneartion in the near future"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXGugCJCV_lZ"
      },
      "source": [
        "def make_prefs_dataset(dataset):\n",
        "  prefixes = data[\"start\"].apply(lambda x: re.findall(r\"[\\w ,]*[!.)]\", x)[0])\n",
        "  bad_places = []\n",
        "  bad_values = [\"Junior)\", \"Привет, меня зовут Ольга Ищу Java разработчика Senior.\", \")\", \n",
        "                \" Олег, cпeциaлиcт пo пoиcку кaндидaтoв кoмпaнии Сбер Пишу, чтобы предложить вакансию Android Developer.\"]\n",
        "  for place in range(len(data)):\n",
        "    value = prefixes[place]\n",
        "    if value in bad_values:\n",
        "      bad_places.append(place)\n",
        "  \n",
        "  prefixes[18] = \"Привет, меня зовут Ольга\"\n",
        "  prefixes[40] = \"Добрый день, Павел :) Меня зовут Ольга, я представляю кадровое ИТ агентство.\"\n",
        "  prefixes[42] = \"Здравствуйте, Павел Я - Олег, cпeциaлиcт пo пoиcку кaндидaтoв кoмпaнии Сбер\"\n",
        "  prefixes[68] = \"Компания Сбер\"\n",
        "\n",
        "  prefixes = prefixes.drop_duplicates()\n",
        "  pd.DataFrame([prefixes.values]).to_csv(\"GenerationPrefixes.csv\", sep=\";\", index=False) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ofWkGM4mPET"
      },
      "source": [
        "### Save CSV-file with prefixes for generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Eg6e29RnuXx"
      },
      "source": [
        "def load_prefixes():\n",
        "  return pd.read_csv(\"/content/drive/MyDrive/course_work/GenerationPrefixes.csv\", sep=\";\").transpose().rename(columns={0: \"message\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvw3dZ5wlX3N"
      },
      "source": [
        "### Make neseccity files (train.txt; valid.txt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kGdLaTMlakb"
      },
      "source": [
        "def make_train_and_valid_files(dataset, train_messages=71):\n",
        "  train_file = open(\"train.txt\", \"w\")\n",
        "  valid_file = open(\"valid.txt\", \"w\")\n",
        "  \n",
        "  # first *train_messages* to train\n",
        "  for sentence in dataset[\"start\"].values[:train_messages]:\n",
        "    train_file.write(f\"{sentence}\\n\")\n",
        "  \n",
        "  # last *86 - train_messages* for validation\n",
        "  for sentence in dataset[\"start\"].values[train_messages:]:\n",
        "    valid_file.write(f\"{sentence}\\n\")\n",
        "  \n",
        "  train_file.close()\n",
        "  valid_file.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3QeL_6Co8HS"
      },
      "source": [
        "make_train_and_valid_files(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n420HPkHpJ4T"
      },
      "source": [
        "prefixes = load_prefixes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWZ4QL5oXCpH"
      },
      "source": [
        "# Work with rugpt3small_based_on_gpt2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvxfizbcoWtK"
      },
      "source": [
        "### Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbLEkk1TnP9C"
      },
      "source": [
        "!export PYTHONPATH=${PYTHONPATH}:/ru-gpts/\n",
        "!CUDA_VISIBLE_DEVICES=0 python ru-gpts/pretrain_transformers.py \\\n",
        "    --output_dir=small_results \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
        "    --do_train \\\n",
        "    --train_data_file=train.txt \\\n",
        "    --do_eval \\\n",
        "    --eval_data_file=valid.txt \\\n",
        "    --per_gpu_train_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --block_size 1024 \\\n",
        "    --overwrite_output_dir"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTefvbRF1b8H"
      },
      "source": [
        "### Manually generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXZ4YyKytWr8"
      },
      "source": [
        "small_gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"small_results\")\n",
        "small_gpt_model = GPT2LMHeadModel.from_pretrained(\"small_results\")\n",
        "model.cuda()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MwW3uW0rSZk"
      },
      "source": [
        "Model generate too long sentences for mine task of headings generating. So try to crop everythin after line break"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSSsLFX3goQ_"
      },
      "source": [
        "def generate_by_prefix(model, tokenizer, input_txt, max_len=200):\n",
        "  inpt = tokenizer.encode(input_txt, return_tensors=\"pt\")\n",
        "  if torch.cuda.is_available():\n",
        "    inpt = inpt.cuda()\n",
        "  out = model.generate(inpt, max_length=max_len, repetition_penalty=5.0, do_sample=True, top_k=5, top_p=0.95, temperature=1)\n",
        "  return tokenizer.decode(out[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to make an excel file with generated headings"
      ],
      "metadata": {
        "id": "BT_TMMGWjcsq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR2t18QFkymc"
      },
      "source": [
        "def make_file_with_outputs(model, tokenizer, file_name):\n",
        "  generated = []\n",
        "  for pref in prefixes[\"message\"].values:\n",
        "    generated.append(generate_by_prefix(model, tokenizer, pref))\n",
        "  generated = list(map(lambda x: x.split(\"\\n\")[0], generated))\n",
        "  pd.DataFrame(generated).to_excel(file_name, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krvKXvNfm6Ar"
      },
      "source": [
        "make_file_with_outputs(small_gpt_model, small_gpt_tokenizer, \"small_gpt.xlsx\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ8wIoIU2r_Y"
      },
      "source": [
        "# Work with rugpt3medium_based_on_gpt2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHZGKnir7arH"
      },
      "source": [
        "### Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZfdamT42s7L"
      },
      "source": [
        "!export PYTHONPATH=${PYTHONPATH}:/ru-gpts/\n",
        "!CUDA_VISIBLE_DEVICES=0 python ru-gpts/pretrain_transformers.py \\\n",
        "    --output_dir=medium_results \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=sberbank-ai/rugpt3medium_based_on_gpt2 \\\n",
        "    --do_train \\\n",
        "    --train_data_file=train.txt \\\n",
        "    --do_eval \\\n",
        "    --eval_data_file=valid.txt \\\n",
        "    --per_gpu_train_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --block_size 128 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --per_gpu_eval_batch_size 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrUQM2H0nuLj"
      },
      "source": [
        "### Manually generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OImpL9XznsBV"
      },
      "source": [
        "medium_gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"medium_results\")\n",
        "medium_gpt_model = GPT2LMHeadModel.from_pretrained(\"medium_results\")\n",
        "medium_gpt_model.cuda()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyKzDpUTqytd"
      },
      "source": [
        "make_file_with_outputs(medium_gpt_model, medium_gpt_tokenizer, \"medium_gpt.xlsx\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWpK3UVxEmJq"
      },
      "source": [
        "#Worj with Dungeon model (Probably GPT-2 or GPT-3 finetuned on Russian fairy tales)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I didn't catch how to finetune this model, but decided to generate smth with it just for fun\n",
        "\n",
        "### P.S. Now, approximately after 1 month since project end, I have some ideas, but it's too late, ahahah. Probably I'll improve it project once"
      ],
      "metadata": {
        "id": "3V0FITK-ig65"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRZYLwalBh7Y"
      },
      "source": [
        "dungeon_tokenizer = AutoTokenizer.from_pretrained(\"Mary222/MADE_AI_Dungeon_model_RUS\")\n",
        "dungeon_model = AutoModelWithLMHead.from_pretrained(\"Mary222/MADE_AI_Dungeon_model_RUS\")\n",
        "dungeon_model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKOnt9w5Bh9G"
      },
      "source": [
        "make_file_with_outputs(dungeon_model, dungeon_tokenizer, \"unfinetune_dungeon.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8DFkYosRQyB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
