{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "count_metrics.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fao1S8ooid8t"
      },
      "source": [
        "# Install required enviroment and import packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "JqbbKTRTl9bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B9zgoMShHVb"
      },
      "source": [
        "import pandas as pd\n",
        "import regex as re\n",
        "from collections import Counter\n",
        "import sys\n",
        "from unicodedata import category\n",
        "import pymorphy2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIDz16AVaVOS",
        "outputId": "5ebe8700-6a56-4a71-a72f-30df04743bfd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should be already familiar with this function, haha"
      ],
      "metadata": {
        "id": "qp5O9_NhlqjH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxSHiIAqWLPr"
      },
      "source": [
        "def preproc_data(dataset):\n",
        "  dataset = csv_deEmojify(dataset)\n",
        "  try:\n",
        "    dataset = dataset.rename(columns={\"Заголовок + конец сообщения\": \"start_end\", \"Только заголовок\": \"start\"})\n",
        "    dataset = dataset[[\"start_end\", \"start\"]]\n",
        "  except:\n",
        "    print(\"noup\")\n",
        "  \n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load data"
      ],
      "metadata": {
        "id": "PV6le41kkmYP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N-lD5qKk9mC"
      },
      "source": [
        "HR = pd.read_excel(\"/content/drive/MyDrive/course_work/Headings_wo_emoji.xlsx\")\n",
        "HR_headings = HR.start_end.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_lT2NHEiWrW"
      },
      "source": [
        "small_GPT_headings = pd.read_excel(\"/content/drive/MyDrive/course_work/work_with_ends/small_gpt.xlsx\").rename(columns={0: \"mess\"})\n",
        "small_GPT_headings = small_GPT_headings[\"mess\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3q9GFQcjJZ8"
      },
      "source": [
        "medium_GPT_headings = pd.read_excel(\"/content/drive/MyDrive/course_work/work_with_ends/medium_gpt.xlsx\").rename(columns={0: \"mess\"})\n",
        "medium_GPT_headings = medium_GPT_headings[\"mess\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5H9AN5OVwb9"
      },
      "source": [
        "dungeon = pd.read_excel(\"/content/drive/MyDrive/course_work/work_with_ends/unfinetune_dungeon.xlsx\").rename(columns={0: \"mess\"})\n",
        "dungeon_headings = dungeon.mess.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMJb_j-2fMB5"
      },
      "source": [
        "# Let's count some metrics manually instead of write parser for SEO-analysis in the internet (for instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oXN1fbYfOp4"
      },
      "source": [
        "### Metrics I'm gonna count:\n",
        "\n",
        "1. An amount of symbols\n",
        "\n",
        "2. An amount of words\n",
        "\n",
        "3. An amount of unique words\n",
        "\n",
        "4. A classic text nausea\n",
        "\n",
        "5. An amount of symbols of punctuation\n",
        "\n",
        "6. A repeat rate\n",
        "\n",
        "7. A degree of water\n",
        "\n",
        "8. An amount for stop-words (words, that don't have any meaning beyond a context, are named stop-words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to count an amount of symbols"
      ],
      "metadata": {
        "id": "4onRU--7mEGY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6gCTbvfp416"
      },
      "source": [
        "punctuation_chars =  [chr(i) for i in range(sys.maxunicode) \n",
        "                             if category(chr(i)).startswith(\"P\")]\n",
        "def count_punc(string):\n",
        "  count_punc = 0\n",
        "  for symb in string:\n",
        "    if symb in punctuation_chars:\n",
        "      count_punc += 1\n",
        "      \n",
        "  return count_punc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to count an amount of stop-words (you must have a file with russian stop-words for it)"
      ],
      "metadata": {
        "id": "vKllnBfbmMkz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbpyvFlAkwMk"
      },
      "source": [
        "stop_words = open(\"/content/drive/MyDrive/course_work/stop_words_ru.txt\", \"r\").read()\n",
        "\n",
        "def count_stop_words(string):\n",
        "  n_stop_words = 0\n",
        "  for word in string.split():\n",
        "    if word in stop_words:\n",
        "      n_stop_words += 1\n",
        "  return n_stop_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to a little bit preprocessing string for further metrcis exploring"
      ],
      "metadata": {
        "id": "knJ0rfFpmTIe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho4KedNtqGVh"
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def preproc_string(string):\n",
        "  string = string.lower()\n",
        "  for symb in string:\n",
        "    if symb == \"-\":\n",
        "      string = string.replace(symb, \" \")\n",
        "    elif symb in punctuation_chars:\n",
        "      string = string.replace(symb, \"\")\n",
        "  \n",
        "  return \" \".join([morph.parse(word)[0][2] for word in string.split()])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trash = [\"-\", \"—\", \":)\", \")\", \":\", \"(\", \"(:\", \"!\", \"?\", \",\", \".\", \"\"]\n",
        "pattern = r\"[!?.]\"\n",
        "vowels = [\"a\", \"у\", \"о\", \"и\", \"э\", \"е\", \"ё\", \"я\", \"ю\", \"ы\", \"a\", \"e\", \"u\", \"i\", \"o\", \"y\"]\n",
        "\n",
        "def count_words(string):\n",
        "  words = list(filter(lambda x: x not in trash, string.split()))\n",
        "  return len(words)\n",
        "\n",
        "def count_sent(string):\n",
        "  sentences = list(filter(lambda x: x not in trash, re.split(pattern, string)))\n",
        "  return len(sentences)\n",
        "\n",
        "def count_sylls(string):\n",
        "  counter = 0\n",
        "  for char in string.lower():\n",
        "    if char in vowels:\n",
        "      counter += 1\n",
        "  return counter \n",
        "\n",
        "def count_flash(string):\n",
        "  n_words = count_words(string)\n",
        "  n_sents = count_sent(string)\n",
        "  n_sylls = count_sylls(string)\n",
        "  flash = 206.835 - 1.05*n_words/n_sents - 84.6*n_sylls/n_words\n",
        "  if flash > 100:\n",
        "    return 100\n",
        "  if flash < 0:\n",
        "    return 0\n",
        "  return flash"
      ],
      "metadata": {
        "id": "Q3gbMR9_QPnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# изменим порядок\n",
        "\n",
        "metrics = metrics[['Unnamed: 0', 'message', 'mess_len', 'n_words', 'n_unique',\n",
        "                    'repeat_rate', 'puke', 'puke_rate', 'n_stop', 'water_rate',\n",
        "                    'flash', 'n_punc', 'model']]"
      ],
      "metadata": {
        "id": "vLS6bLlXWR-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.to_excel(\"all_metrics.xlsx\")"
      ],
      "metadata": {
        "id": "Pno0PpaoWpMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLUuN3kpgp_N"
      },
      "source": [
        "# подсчитываем длину сообщения, количество слов, количество знаков препинания, часть воды\n",
        "# количество уникальных слов, степень повторенности, классическую тошноту, количество стоп-слов\n",
        "\n",
        "def count_metrics(string):\n",
        "  n_chars = len(string)\n",
        "  n_punc = count_punc(string)\n",
        "  flash = count_flash(string)\n",
        "\n",
        "  string = preproc_string(string)\n",
        "  n_stop_words = count_stop_words(string)\n",
        "  n_words = len(string.split())\n",
        "  n_unique_words = len(list(set(string.split())))\n",
        "  repeat_degree = round((n_words - n_unique_words)/n_words, 4)\n",
        "  puke_degree = max(Counter(string.split()).values())**0.5\n",
        "  water_degree = round(n_stop_words / n_unique_words, 4)\n",
        "\n",
        "  return n_chars, n_words, n_unique_words, n_punc, repeat_degree, puke_degree/n_words, water_degree, flash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yWDu4JDuUAQ"
      },
      "source": [
        "metrics = [\"n_chars\", \"n_words\", \"n_unique_words\", \"n_punc\", \"repeat_rate\", \"puke_rate\", \"water_rate\", \"flash\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TXcqhRy0c-nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khk2GuQQuQ-d"
      },
      "source": [
        "# Count metrcis for original HR messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzr2wttRf-0-"
      },
      "source": [
        "HR_metrics = []\n",
        "for mess in HR_headings:\n",
        "  HR_metrics.append(count_metrics(mess))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huCFRT6Fu47R"
      },
      "source": [
        "HR_metrics = pd.DataFrame(HR_metrics, columns=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On1J2Lq0uoab"
      },
      "source": [
        "# Count metrcis for generated GPT-2 messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBxLljqElbxs"
      },
      "source": [
        "small_gpt_metrics = []\n",
        "for mess in small_GPT_headings:\n",
        "  small_gpt_metrics.append(count_metrics(mess))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVfhwLkYvCjZ"
      },
      "source": [
        "small_gpt_metrics = pd.DataFrame(small_gpt_metrics, columns=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qZW5LiEuwZp"
      },
      "source": [
        "medium_gpt_metrics = []\n",
        "for mess in medium_GPT_headings:\n",
        "  medium_gpt_metrics.append(count_metrics(mess))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5okyZwpLvDNz"
      },
      "source": [
        "medium_gpt_metrics = pd.DataFrame(medium_gpt_metrics, columns=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGY0JRj-YOUd"
      },
      "source": [
        "# For unfinetuned Dungeon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thHYYMyOYSnx"
      },
      "source": [
        "dungeon_metrics = []\n",
        "for mess in dungeon_headings:\n",
        "  dungeon_metrics.append(count_metrics(mess))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv8Jx2mwYZKq"
      },
      "source": [
        "dungeon_metrics = pd.DataFrame(dungeon_metrics, columns=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU_ifOE0vK_P"
      },
      "source": [
        "# Save all this data to an excel-files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNJji670v_GH"
      },
      "source": [
        "HR_metrics.to_excel(\"HR_metrics.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1r2q5YmwHJ8"
      },
      "source": [
        "small_gpt_metrics.to_excel(\"small_gpt_metrics.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkZl9nMowPoZ"
      },
      "source": [
        "medium_gpt_metrics.to_excel(\"medium_gpt_metrics.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWMjK4_3YQdL"
      },
      "source": [
        "dungeon_metrics.to_excel(\"unfinetuned_dungeon_metrics.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iCOm75SJnRbp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}